# -*- coding: utf-8 -*-
"""AIUsageAnalysis (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p8drBqhQTt6pKyCjY_JtRK4pqa6YUYL3

## AI Usage Analysis based on R-GAIDT Intervention
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# New section"""

df = pd.read_csv('/content/Post-interventionOrigninalAIusage_ethical_bias.csv')

df.info()

df_designthinking = df.iloc[:, [4,5,6,7]]

df_designthinking

for col in df_designthinking.columns:
    print(f'Unique values for column {col}: {df_designthinking[col].unique()}')

# Drop NaN values from the 'GenAI-testing' column (assuming it's one of the columns in df_designthinking)
# Replace 'GenAI-testing' with the actual column name if it is different.
df_designthinking = df_designthinking.dropna(subset=['GenAI-testing'])

for col in df_designthinking.columns:
    print(f'Unique values for column {col}: {df_designthinking[col].unique()}')

# Define the mapping dictionary
value_mapping = {
    'Never': 0,
    'Sometimes': 1,
    'Often': 2,
    'Always': 3
}

# Apply the mapping to relevant columns using .loc
columns_to_map = ['GenAI-empathy', 'GenAI-ideation', 'GenAI-prototyping', 'GenAI-testing']

for col in columns_to_map:
    df_designthinking.loc[:, col] = df_designthinking[col].map(value_mapping)

# Display the first few rows to verify the mapping
print(df_designthinking.head())

"""## AI usage analysis"""

import pandas as pd
import matplotlib.pyplot as plt

# Assuming df_designthinking contains your data
# Count occurrences of each category in each column
usage_counts = df_designthinking.apply(lambda col: col.value_counts()).fillna(0)

# Rename columns to be more user-friendly
usage_counts = usage_counts.rename(columns={
    'GenAI-empathy': 'Empathy',
    'GenAI-ideation': 'Ideation',
    'GenAI-prototyping': 'Prototyping',
    'GenAI-testing': 'Testing'
})

# Set up bar chart with lighter colors and hatching
fig, ax = plt.subplots(figsize=(8, 5))
bar_width = 0.2  # Width of each bar
x = range(len(usage_counts.columns))  # X positions for the bars
hatches = ['/', '\\', '|', '-']  # Patterns for bars

# Lighter color palette
colors = plt.cm.Pastel1.colors

# Plot each usage level
for i, (level, hatch) in enumerate(zip(usage_counts.index, hatches)):
    ax.bar(
        [pos + i * bar_width for pos in x],  # Adjusted x positions
        usage_counts.loc[level],  # Heights of bars
        width=bar_width,
        label=f'{level} ({["Never", "Sometimes", "Often", "Always"][i]})',
        hatch=hatch,
        color=colors[i % len(colors)],  # Use pastel colors
        edgecolor='black'
    )

# Customize axes and labels
ax.set_xlabel('Design Thinking Stages', fontsize=10)
ax.set_ylabel('Frequency of Generative AI Usage', fontsize=10)
ax.set_xticks([pos + 1.5 * bar_width for pos in x])  # Adjusted x-tick positions
ax.set_xticklabels(['Empathy', 'Ideation', 'Prototyping', 'Testing'], fontsize=10)
ax.legend(title='Usage Levels', fontsize=10, loc='upper left')

# Adjust layout for better fit
plt.tight_layout()
plt.savefig('ai_usage_analysis.png',dpi=300)

# Display the plot
plt.show()

# Count occurrences of each category in each column
usage_counts = df_designthinking.apply(lambda col: col.value_counts()).fillna(0)

# Rename columns to be more user-friendly
usage_counts = usage_counts.rename(columns={
    'GenAI-empathy': 'Empathy',
    'GenAI-ideation': 'Ideation',
    'GenAI-prototyping': 'Prototyping',
    'GenAI-testing': 'Testing'
})

# Print the usage counts
print(usage_counts)

df = pd.read_csv('/content/Post-interventionOrigninalAIusage_ethical_bias.csv')

df.info()

# Assuming df is already defined from the previous code block
ethical_df = df.iloc[:, [0, 1, 2, 3]]

ethical_df

for col in ethical_df.columns:
    print(f'Unique values for column {col}: {ethical_df[col].unique()}')

# Strip any leading or trailing spaces from the column names
ethical_df.columns = ethical_df.columns.str.strip()

# Now rename the column
ethical_df = ethical_df.rename(columns={'Generative AI tools & bias into the design process': 'Generative AI tools and bias into the design process'})

# Verify the new column names
print(ethical_df.columns)

ethical_df.info()

import pandas as pd

# Strip any extra spaces from the column names to avoid issues
ethical_df.columns = ethical_df.columns.str.strip()

# Create a dictionary for each column to map the categorical values to numerical values
mapping_tools_bias = {
    'Not at All': 0,
    'Slightly Increased': 1,
    'Moderately Increased': 3,
    'Significantly Increased': 4
}

mapping_confidence = {
    'Very confident': 3,
    'Moderately confident': 2,
    'Slightly confident': 1
}

mapping_responsibility = {
    'Very responsible': 3,
    'Responsible': 2,
    'Moderately responsible': 1
}

mapping_awareness = {
    'Slightly Increased': 1,
    'Moderately Increased': 3,
    'Greatly Increased': 4,
    'Significantly Increased': 5
}

# Apply the mappings to the respective columns in ethical_df
ethical_df['Generative AI tools and bias into the design process'] = ethical_df['Generative AI tools and bias into the design process'].map(mapping_tools_bias)
ethical_df['How confident are you in your understanding of how the AI tools make decisions and generate outputs?'] = ethical_df['How confident are you in your understanding of how the AI tools make decisions and generate outputs?'].map(mapping_confidence)
ethical_df['How responsible do you feel for the outcomes generated with the help of AI tools in your project?'] = ethical_df['How responsible do you feel for the outcomes generated with the help of AI tools in your project?'].map(mapping_responsibility)
ethical_df['To what extent did the AI Usage Analysis Module increase your awareness of ethical issues such as intellectual property and data privacy?'] = ethical_df['To what extent did the AI Usage Analysis Module increase your awareness of ethical issues such as intellectual property and data privacy?'].map(mapping_awareness)

# Display the dataframe to verify
print(ethical_df.head())

#--- Analysis of Ethical Awareness ---
# Frequency distribution of ethical awareness levels
ethical_awareness_distribution = ethical_df['To what extent did the AI Usage Analysis Module increase your awareness of ethical issues such as intellectual property and data privacy?'].value_counts()
print("\nEthical Awareness Distribution:")
print(ethical_awareness_distribution)

# Compare ethical awareness with confidence in understanding AI decision-making
ethical_awareness_vs_confidence = ethical_df.groupby('How confident are you in your understanding of how the AI tools make decisions and generate outputs?') \
                                           ['To what extent did the AI Usage Analysis Module increase your awareness of ethical issues such as intellectual property and data privacy?'] \
                                           .mean()
print("\nEthical Awareness vs Confidence in Understanding AI:")
print(ethical_awareness_vs_confidence)

# --- Analysis of Confidence in AI Usage ---
# Frequency distribution of confidence levels
confidence_distribution = ethical_df['How confident are you in your understanding of how the AI tools make decisions and generate outputs?'].value_counts()
print("\nConfidence Distribution:")
print(confidence_distribution)

# Compare confidence with responsibility for AI-generated outcomes
confidence_vs_responsibility = ethical_df.groupby('How confident are you in your understanding of how the AI tools make decisions and generate outputs?') \
                                          ['How responsible do you feel for the outcomes generated with the help of AI tools in your project?'] \
                                          .mean()
print("\nConfidence vs Responsibility:")
print(confidence_vs_responsibility)

# --- Analysis of Responsibility ---
# Frequency distribution of responsibility levels
responsibility_distribution = ethical_df['How responsible do you feel for the outcomes generated with the help of AI tools in your project?'].value_counts()
print("\nResponsibility Distribution:")
print(responsibility_distribution)

# Compare responsibility with ethical awareness
responsibility_vs_awareness = ethical_df.groupby('How responsible do you feel for the outcomes generated with the help of AI tools in your project?') \
                                       ['To what extent did the AI Usage Analysis Module increase your awareness of ethical issues such as intellectual property and data privacy?'] \
                                       .mean()
print("\nResponsibility vs Ethical Awareness:")
print(responsibility_vs_awareness)

# --- Correlation Analysis ---
# Correlation matrix for all mapped columns to find relationships between confidence, responsibility, awareness, and tools bias
correlation_matrix = ethical_df.corr()
print("\nCorrelation Matrix:")
print(correlation_matrix)

# --- Visualizations (Optional) ---
import matplotlib.pyplot as plt
import seaborn as sns

# Plotting the correlation heatmap for better understanding of relationships
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)
plt.title("Correlation Heatmap")
plt.show()

import matplotlib.pyplot as plt

# Create a figure with 3 subplots (1 row, 3 columns)
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

# Bar plot for Ethical Awareness Distribution
ethical_df['To what extent did the AI Usage Analysis Module increase your awareness of ethical issues such as intellectual property and data privacy?'].value_counts().plot(
    kind='bar', color='skyblue', ax=axes[0], hatch='\\', edgecolor='black', width=0.8)
axes[0].set_xlabel('Ethical Awareness Level', fontsize=12)
axes[0].set_ylabel('Frequency', fontsize=12)
axes[0].tick_params(axis='x', rotation=45, labelsize=10)
axes[0].tick_params(axis='y', labelsize=10)

# Bar plot for Confidence Distribution
ethical_df['How confident are you in your understanding of how the AI tools make decisions and generate outputs?'].value_counts().plot(
    kind='bar', color='lightgreen', ax=axes[1], hatch='//', edgecolor='black', width=0.8)
axes[1].set_xlabel('Confidence Use of AI', fontsize=12)
axes[1].set_ylabel('Frequency', fontsize=12)
axes[1].tick_params(axis='x', rotation=45, labelsize=10)
axes[1].tick_params(axis='y', labelsize=10)

# Bar plot for Responsibility Distribution
ethical_df['How responsible do you feel for the outcomes generated with the help of AI tools in your project?'].value_counts().plot(
    kind='bar', color='lightcoral', ax=axes[2], hatch='x', edgecolor='black', width=0.8)
axes[2].set_xlabel('Responsible Use of AI', fontsize=12)
axes[2].set_ylabel('Frequency', fontsize=12)
axes[2].tick_params(axis='x', rotation=45, labelsize=10)
axes[2].tick_params(axis='y', labelsize=10)

# Adjust layout for better spacing
plt.tight_layout()
plt.savefig('awareness_ethical_analysis.png',dpi=300)

# Show the plot
plt.show()

# Print results for Ethical Awareness Distribution
print("Ethical Awareness Distribution:")
print(ethical_df['To what extent did the AI Usage Analysis Module increase your awareness of ethical issues such as intellectual property and data privacy?'].value_counts())

# Print results for Confidence Distribution
print("\nConfidence in Understanding AI Decision-Making:")
print(ethical_df['How confident are you in your understanding of how the AI tools make decisions and generate outputs?'].value_counts())

# Print results for Responsibility Distribution
print("\nResponsibility for Outcomes Generated by AI:")
print(ethical_df['How responsible do you feel for the outcomes generated with the help of AI tools in your project?'].value_counts())

ethical_df.info()

ethical_df.to_csv('ethical_df.csv', index=False)

ethical_df_processed = pd.read_csv('/content/ethical_df.csv')

ethical_df_processed

import seaborn as sns
import matplotlib.pyplot as plt

# Rename the column 'Generative AI tools and bias into the design process' to 'Bias in Generative AI'
ethical_df = ethical_df.rename(columns={
    'Generative AI tools and bias into the design process': 'Bias in Generative AI'
})

# Correlation matrix for numerical columns
correlation_matrix = ethical_df.corr()

# Heatmap for correlation matrix
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)
plt.tight_layout()
plt.savefig('correlation_heatmapAIusage.png',dpi=300)
#plt.title('Correlation Heatmap of AI Usage Ethics Data')
plt.show()

print('Correlation AI Usage Ethics Data')
ethical_df.corr()

"""## pre- and post-intervention survey responses to assess changes in students' ethical awareness regarding AI usage.

## Comparison
"""

ethical_post= pd.read_csv('/content/Post-interventionOrigninalAIusage_ethical_bias.csv')
ethical_pre= pd.read_csv('/content/Preinterventionethicalawareness.csv')

ethical_post

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming 'ethical_pre' and 'ethical_post' dataframes are already loaded

# Mappings for Pre-Intervention (Familiarity levels)
mapping_pre_intervention = {
    'Slightly Familiar': 1,
    'Moderately Familiar': 3,
    'Very Familiar': 5
}

# Mappings for Post-Intervention (Awareness levels)
mapping_post_intervention = {
    'Slightly Increased': 1,
    'Moderately Increased': 3,
    'Greatly Increased': 5
}

# Apply the mapping for pre-intervention column (index 0 in ethical_pre)
ethical_pre['Ethical Awareness'] = ethical_pre.iloc[:, 0].map(mapping_pre_intervention)

# Apply the mapping for post-intervention column (index 3 in ethical_post)
ethical_post['Ethical Awareness'] = ethical_post.iloc[:, 3].map(mapping_post_intervention)

# Calculate and display the mean, median, and mode of the 'Ethical Awareness' column for both pre- and post-intervention
mean_pre_intervention = ethical_pre['Ethical Awareness'].mean()
mean_post_intervention = ethical_post['Ethical Awareness'].mean()

median_pre_intervention = ethical_pre['Ethical Awareness'].median()
median_post_intervention = ethical_post['Ethical Awareness'].median()

mode_pre_intervention = ethical_pre['Ethical Awareness'].mode()[0]  # mode() returns a series
mode_post_intervention = ethical_post['Ethical Awareness'].mode()[0]  # mode() returns a series

print(f"Mean Ethical Awareness Pre-Intervention: {mean_pre_intervention}")
print(f"Mean Ethical Awareness Post-Intervention: {mean_post_intervention}")
print(f"Median Ethical Awareness Pre-Intervention: {median_pre_intervention}")
print(f"Median Ethical Awareness Post-Intervention: {median_post_intervention}")
print(f"Mode Ethical Awareness Pre-Intervention: {mode_pre_intervention}")
print(f"Mode Ethical Awareness Post-Intervention: {mode_post_intervention}")

# Visualize the distribution of the Ethical Awareness values for both pre- and post-intervention
plt.figure(figsize=(8, 6))

# Plotting pre-intervention values with KDE
sns.histplot(ethical_pre['Ethical Awareness'], kde=True, color='lightblue', label='Pre-Intervention', stat='density', bins=5)

# Plotting post-intervention values with KDE
sns.histplot(ethical_post['Ethical Awareness'], kde=True, color='lightgreen', label='Post-Intervention', stat='density', bins=5)

# Adding lines for Mean, Median, and Mode for Pre-Intervention
plt.axvline(mean_pre_intervention, color='blue', linestyle='dashed', linewidth=2, label=f'Mean Pre: {mean_pre_intervention:.2f}')
plt.axvline(median_pre_intervention, color='blue', linestyle='solid', linewidth=2, label=f'Median Pre: {median_pre_intervention:.2f}')
plt.axvline(mode_pre_intervention, color='blue', linestyle='dotted', linewidth=2, label=f'Mode Pre: {mode_pre_intervention:.2f}')

# Adding lines for Mean, Median, and Mode for Post-Intervention
plt.axvline(mean_post_intervention, color='green', linestyle='dashed', linewidth=2, label=f'Mean Post: {mean_post_intervention:.2f}')
plt.axvline(median_post_intervention, color='green', linestyle='solid', linewidth=2, label=f'Median Post: {median_post_intervention:.2f}')
plt.axvline(mode_post_intervention, color='green', linestyle='dotted', linewidth=2, label=f'Mode Post: {mode_post_intervention:.2f}')

# Title and labels
#plt.title('Distribution of Ethical Awareness Pre and Post Intervention')
plt.xlabel('Ethical Awareness of AI Usage Score')
plt.ylabel('Density')
plt.legend()

# Show plot
plt.tight_layout()
plt.savefig('ethical_awareness_pre_post.png',dpi=300)
plt.show()

import os
import zipfile
from google.colab import files

# Specify the directory and the extensions you want to download
directory = '/content/'
extensions = ['.csv', '.png']  # Add more extensions as needed

# List all files in the directory
files_in_directory = os.listdir(directory)

# Filter files with the specified extensions
files_to_download = [file for file in files_in_directory if any(file.endswith(ext) for ext in extensions)]

# Define the name of the zip file
zip_filename = '/content/EthicalAIusage_analysis.zip'

# Create a zip file and add the matching files to it
with zipfile.ZipFile(zip_filename, 'w') as zipf:
    for file in files_to_download:
        file_path = os.path.join(directory, file)
        zipf.write(file_path, os.path.basename(file))  # Add file to zip

# Download the zip file
files.download(zip_filename)